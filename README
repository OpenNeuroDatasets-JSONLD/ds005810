Summary
----------
The human brain can rapidly recognize meaningful objects from natural scenes encountered in everyday life. Neuroimaging with large-scale naturalistic stimuli is increasingly employed to elucidate these neural mechanisms of object recognition across these rich and daily natural scenes. However, most existing large-scale neuroimaging datasets with naturalistic stimuli primarily rely on functional magnetic resonance imaging (fMRI), which provides high spatial resolution to characterize spatial representation patterns, is limited in capturing the temporal dynamics inherent in visual cognitive processing. To address this limitation, we extended our previously collected Natural Object Dataset-fMRI (NOD-fMRI) by collecting both magnetoencephalography (MEG) and electroencephalography (EEG) data from the same subjects while viewing the same set of naturalistic stimuli. As a result, the NOD uniquely integrates three different modalities—fMRI, MEG, and EEG—thus offering promising avenues to examine brain activity induced by naturalistic stimuli with both high spatial and high temporal resolutions. Additionally, the NOD encompasses a diverse array of naturalistic stimuli and a broader subject pool, which enables researchers to explore differences in neural activation patterns across both stimuli and subjects. We anticipate that the NOD dataset will serve as a valuable resource for advancing our understanding of the cognitive and neural mechanisms underlying object recognition. (the EEG data's accession number is ds005811)

Data records
----------
The raw data from each subject are stored in the "sub-<ID>" directory, while preprocessed data and epoch data are stored in the "derivatives/preprocessed/raw" and "derivatives/preprocessed/epochs" directories, respectively.

Stimulus images.
The stimuli images used for MEG and EEG are identical and are stored in the "stimuli/ImageNet" directory. Images within the folder are named in the format "<synsetID>_<imageID>.JPEG", where synsetID is the ILSVRC category information, and imageID is the unique number for the image within that category. The image metadata, including category information, is available in the table files under "stimuli/metadata".

Raw data. 
Raw MEG and EEG data are stored in BIDS format. Each subject's directory contains multiple session folders, designated as "ses-<sesID>". The "ses-MRI/anat" directory contains the subject's structural MRI images. The comprehensive trial information for each subject is documented in the file " derivatives/detailed_events/sub-<subID>_events.csv" in which each row corresponds to a trial, and each column contains metadata for that trial, including the session and run number, category information of the stimuli, and subject response.

Preprocessed data.
The full time series data of preprocessed data are archived in the "derivatives/raw" directory, named as "sub-<subID>_ses-<sesID>_task-ImageNet_run-<runID>_<meg>_clean.fif". The epoch data derived from preprocessed data are stored within the "derivatives/epochs" directory. In this directory, all data for each subject are concatenated into a single file, labelled as "sub-<subID>_epo.fif". The trial information within each subject's epochs data can be accessed via the metadata of the epochs data which are aligned with the content of the subject's "sub-<subID>_events.csv" file.

References
----------
Appelhoff, S., Sanderson, M., Brooks, T., Vliet, M., Quentin, R., Holdgraf, C., Chaumon, M., Mikulan, E., Tavabi, K., Höchenberger, R., Welke, D., Brunner, C., Rockhill, A., Larson, E., Gramfort, A. and Jas, M. (2019). MNE-BIDS: Organizing electrophysiological data into the BIDS format and facilitating their analysis. Journal of Open Source Software 4: (1896).https://doi.org/10.21105/joss.01896

Niso, G., Gorgolewski, K. J., Bock, E., Brooks, T. L., Flandin, G., Gramfort, A., Henson, R. N., Jas, M., Litvak, V., Moreau, J., Oostenveld, R., Schoffelen, J., Tadel, F., Wexler, J., Baillet, S. (2018). MEG-BIDS, the brain imaging data structure extended to magnetoencephalography. Scientific Data, 5, 180110.https://doi.org/10.1038/sdata.2018.110

